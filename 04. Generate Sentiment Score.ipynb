{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2acb1c40",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f955945b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\sentiment_3_8\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\eikde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\eikde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\eikde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#!pip install pandas_datareader to validate crypto pricing with specific date\n",
    "import pandas_datareader as web\n",
    "import datetime as dt\n",
    "from datetime import date\n",
    "import seaborn as sns\n",
    "from numerize import numerize\n",
    "import torch #torch first before matplotlib, otherwise the library will crash the environment. \n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#NLP libraries\n",
    "import re\n",
    "# Import nltk modules and download dataset\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "#import FinBert library\n",
    "from textblob import TextBlob\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa6445e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract data libraries\n",
    "import requests\n",
    "import dateutil.parser\n",
    "import unicodedata\n",
    "import time\n",
    "from searchtweets import load_credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a92ff15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eikde\\source\\repos\\exploration\\STEPN\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83e64204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eikde\\source\\repos\\exploration\\STEPN\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "from finbert import *\n",
    "import finbert.utils as tools\n",
    "from finbert.finbert import predict\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "project_dir = Path.cwd()\n",
    "print(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "216639cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to check whether torch is available. Torch library is important for NLP and BERT.\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdbd73c",
   "metadata": {},
   "source": [
    "# Preprocessing Text\n",
    "\n",
    "Additional filter if needed, can be added on into preprocess_word function. This will help us to reuse this function to remove unnessary text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a573a0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a function that to help preprocessing the message to a proper text for analysis\n",
    "def preprocess_word(message):\n",
    "    \"\"\"\n",
    "    This function takes a string as input, then performs these operations: \n",
    "        - lowercase\n",
    "        - remove URLs\n",
    "        - remove ticker symbols \n",
    "        - removes punctuation\n",
    "        - tokenize by splitting the string on whitespace \n",
    "        - removes any single character tokens\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        message : The text message to be preprocessed.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        tokens: The preprocessed text into tokens.\n",
    "    \"\"\" \n",
    "    # Lowercase the message\n",
    "    try:\n",
    "        text = str(message).lower()\n",
    "    except:\n",
    "        print(text)\n",
    "    \n",
    "    \n",
    "    # Replace % to percentage only fulfill for number\n",
    "    try:\n",
    "        replace_percent = re.findall('(\\d+(\\.\\d+)?%)', text)\n",
    "        for i in range(len(replace_percent)):\n",
    "            item = re.sub('%', 'percent', replace_percent[i][0])\n",
    "            percent = item.replace(\"percent\",\"%\")\n",
    "            item = re.sub('%', ' percent', replace_percent[i][0])\n",
    "            text = text.replace(percent, item)\n",
    "    except:\n",
    "        print(text)\n",
    "        \n",
    "    # Replace URLs with a space in the message\n",
    "    text = re.sub('https?:\\/\\/[a-zA-Z0-9@:%._\\/+~#=?&;-]*', ' ', text)\n",
    "    \n",
    "    # Replace ticker symbols with a space. The ticker symbols are any stock symbol that starts with $.\n",
    "    text = re.sub('\\$[a-zA-Z0-9]*', ' ', text)\n",
    "    \n",
    "    # Replace usernames with a space. The usernames are any word that starts with @.\n",
    "    text = re.sub('\\@[a-zA-Z0-9]*', ' ', text)\n",
    "\n",
    "    # Replace everything not a letter with a space\n",
    "    text = re.sub('[^a-z0-9.0-9A-Z.]', ' ', text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered = []\n",
    "    filtered = [w for w in word_tokens if not w in stop]\n",
    "    filtered = TreebankWordDetokenizer().detokenize(filtered)\n",
    "    \n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3477647f",
   "metadata": {},
   "source": [
    "# Get predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f903872",
   "metadata": {},
   "source": [
    "With the `predict` function, given a piece of text, we split it into a list of sentences and then predict sentiment for each sentence. The output is written into a dataframe. Predictions are represented in three different columns: \n",
    "\n",
    "1) `logit`: probabilities for each class\n",
    "\n",
    "2) `prediction`: predicted label\n",
    "\n",
    "3) `sentiment_score`: sentiment score calculated as: probability of positive - probability of negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1bddcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load back the pre-train model\n",
    "cl_path = project_dir/'Models'/'classifier_model'/'finbert-sentiment'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(cl_path, cache_dir=None, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cafe48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test statement\n",
    "text = \"animoca leads million funding round hong kong nft platform amid crypto craze ucollex \\\n",
    "        latest funding round comes sales digital collectibles gaining ground city seen increasing \\\n",
    "        number projects launched past year.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cb82ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/09/2022 22:51:34 - INFO - root -   Using device: cuda:0 \n",
      "05/09/2022 22:51:34 - INFO - finbert.utils -   *** Example ***\n",
      "05/09/2022 22:51:34 - INFO - finbert.utils -   guid: 0\n",
      "05/09/2022 22:51:34 - INFO - finbert.utils -   tokens: [CLS] an ##imo ##ca leads million funding round hong kong n ##ft platform amid crypt ##o cr ##az ##e uc ##oll ##ex latest funding round comes sales digital collect ##ible ##s gaining ground city seen increasing number projects launched past year . [SEP]\n",
      "05/09/2022 22:51:34 - INFO - finbert.utils -   input_ids: 101 2019 16339 3540 5260 2454 4804 2461 4291 4290 1050 6199 4132 13463 19888 2080 13675 10936 2063 15384 14511 10288 6745 4804 2461 3310 4341 3617 8145 7028 2015 8550 2598 2103 2464 4852 2193 3934 3390 2627 2095 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/09/2022 22:51:34 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/09/2022 22:51:34 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/09/2022 22:51:34 - INFO - finbert.utils -   label: None (id = 9090)\n",
      "05/09/2022 22:51:36 - INFO - root -   tensor([[ 2.5585, -2.8705, -0.9720]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "result = predict(preprocess_word(text), model,use_gpu=True, gpu_name='cuda:0',batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0cbb9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>logit</th>\n",
       "      <th>prediction</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>animoca leads million funding round hong kong ...</td>\n",
       "      <td>[0.9674181, 0.0042448044, 0.028337164]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.963173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  animoca leads million funding round hong kong ...   \n",
       "\n",
       "                                    logit prediction sentiment_score  \n",
       "0  [0.9674181, 0.0042448044, 0.028337164]   positive        0.963173  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe65a959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/05/2022 20:47:36 - INFO - root -   Using device: cuda:0 \n",
      "05/05/2022 20:47:36 - INFO - finbert.utils -   *** Example ***\n",
      "05/05/2022 20:47:36 - INFO - finbert.utils -   guid: 0\n",
      "05/05/2022 20:47:36 - INFO - finbert.utils -   tokens: [CLS] crypt ##o tax eva ##sion growing around world key global body looking standard ##ize reporting requirements . [SEP]\n",
      "05/05/2022 20:47:36 - INFO - finbert.utils -   input_ids: 101 19888 2080 4171 9345 10992 3652 2105 2088 3145 3795 2303 2559 3115 4697 7316 5918 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/05/2022 20:47:36 - INFO - finbert.utils -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/05/2022 20:47:36 - INFO - finbert.utils -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/05/2022 20:47:36 - INFO - finbert.utils -   label: None (id = 9090)\n",
      "05/05/2022 20:47:36 - INFO - root -   tensor([[ 0.8714, -3.1827,  2.1519],\n",
      "        [ 1.4369, -2.2963,  0.5797]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#Test statement\n",
    "text = \"With crypto tax evasion growing around the world, a key global body is looking\\\n",
    "        to standardize reporting requirements. However, despite good intentions they could be \\\n",
    "        onerous for the industry to comply with.\"\n",
    "result = predict(preprocess_word(text), model,use_gpu=True, gpu_name='cuda:0',batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f79046a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>logit</th>\n",
       "      <th>prediction</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crypto tax evasion growing around world key gl...</td>\n",
       "      <td>[0.2166585, 0.0037592866, 0.7795822]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.212899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>however despite good intentions could onerous ...</td>\n",
       "      <td>[0.690478, 0.016513273, 0.29300866]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.673965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  crypto tax evasion growing around world key gl...   \n",
       "1  however despite good intentions could onerous ...   \n",
       "\n",
       "                                  logit prediction  sentiment_score  \n",
       "0  [0.2166585, 0.0037592866, 0.7795822]    neutral         0.212899  \n",
       "1   [0.690478, 0.016513273, 0.29300866]   positive         0.673965  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f12db3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sentiment is 0.44.\n"
     ]
    }
   ],
   "source": [
    "print(f'Average sentiment is %.2f.' % (result.sentiment_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203ea022",
   "metadata": {},
   "source": [
    "# Generate finance news sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "544df4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read excel file\n",
    "news = pd.read_excel(r\"Data/forbes_news_new.xlsx\")\n",
    "#news = news.drop(['Column1','sentiment_score'], axis=1)\n",
    "news.rename(columns ={\"label\": \"category\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cd12e4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = dt.datetime(2022,4,25)\n",
    "end = dt.datetime(2022,5,9)\n",
    "def filter_news_by_date(start, end, data):\n",
    "    data.date = pd.to_datetime(data.date)\n",
    "    data = data[(data['date'] >= start) & (data['date'] <= end)]\n",
    "    data = data.set_index('date') \n",
    "    data = data.sort_index()\n",
    "    data = data.reset_index()\n",
    "    #data = data.set_index('date')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8bbea13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>number</th>\n",
       "      <th>category</th>\n",
       "      <th>header</th>\n",
       "      <th>desc</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-26</td>\n",
       "      <td>410</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Singapore’s GIC Buying Stake In London’s Paddi...</td>\n",
       "      <td>Singaporean sovereign wealth fund GIC has agre...</td>\n",
       "      <td>Jonathan Burgos</td>\n",
       "      <td>Singapore’s GIC Buying Stake In London’s Paddi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-26</td>\n",
       "      <td>384</td>\n",
       "      <td>Cryptocurrencies</td>\n",
       "      <td>What You Should Know Before Investing In Fidel...</td>\n",
       "      <td>This morning crypto advocates and the crypto c...</td>\n",
       "      <td>Steven Ehrlich</td>\n",
       "      <td>What You Should Know Before Investing In Fidel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-26</td>\n",
       "      <td>383</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Student Loan Forgiveness: 4 People Likely To O...</td>\n",
       "      <td>Here are 4 people who are likely to oppose mas...</td>\n",
       "      <td>Zack Friedman</td>\n",
       "      <td>Student Loan Forgiveness: 4 People Likely To O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-26</td>\n",
       "      <td>382</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Home Buying Is Becoming ‘Unaffordable For Most...</td>\n",
       "      <td>Monthly mortgage payments are up nearly $500 s...</td>\n",
       "      <td>Sergei Klebnikov</td>\n",
       "      <td>Home Buying Is Becoming ‘Unaffordable For Most...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-26</td>\n",
       "      <td>381</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Examining The Ukrainian Tax Implications Of Ru...</td>\n",
       "      <td>Valeria Tarasenko of Dentons Kyiv discusses th...</td>\n",
       "      <td>Tax Notes Staff</td>\n",
       "      <td>Examining The Ukrainian Tax Implications Of Ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>12</td>\n",
       "      <td>Cryptocurrencies</td>\n",
       "      <td>Analyst Believes Bitcoin Could Soon Fall To $3...</td>\n",
       "      <td>Carter Braxton Worth, a technical analyst, bel...</td>\n",
       "      <td>Chuck Jones</td>\n",
       "      <td>Analyst Believes Bitcoin Could Soon Fall To $3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>13</td>\n",
       "      <td>Stock Market</td>\n",
       "      <td>The Best Mid-Cap Dividend Stocks For 2022</td>\n",
       "      <td>Mid-cap dividend stocks are the best bargain o...</td>\n",
       "      <td>Brett Owens</td>\n",
       "      <td>The Best Mid-Cap Dividend Stocks For 2022. Mid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>14</td>\n",
       "      <td>Finance</td>\n",
       "      <td>How To Optimize The Energy We Put Into Financi...</td>\n",
       "      <td>Studies suggest that up to 80% of financial pl...</td>\n",
       "      <td>Tim Maurer</td>\n",
       "      <td>How To Optimize The Energy We Put Into Financi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>7</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Ask Larry: Will The 2022 COLA Apply To Benefit...</td>\n",
       "      <td>Today's Social Security column addresses quest...</td>\n",
       "      <td>Laurence Kotlikoff</td>\n",
       "      <td>Ask Larry: Will The 2022 COLA Apply To Benefit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>0</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Singapore Tycoon Kwek Leng Beng’s CDL Suburban...</td>\n",
       "      <td>City Developments has sold 77% of its resident...</td>\n",
       "      <td>Jonathan Burgos</td>\n",
       "      <td>Singapore Tycoon Kwek Leng Beng’s CDL Suburban...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  number          category  \\\n",
       "0   2022-04-26     410           Finance   \n",
       "1   2022-04-26     384  Cryptocurrencies   \n",
       "2   2022-04-26     383           Finance   \n",
       "3   2022-04-26     382           Finance   \n",
       "4   2022-04-26     381           Finance   \n",
       "..         ...     ...               ...   \n",
       "406 2022-05-09      12  Cryptocurrencies   \n",
       "407 2022-05-09      13      Stock Market   \n",
       "408 2022-05-09      14           Finance   \n",
       "409 2022-05-09       7           Finance   \n",
       "410 2022-05-09       0           Finance   \n",
       "\n",
       "                                                header  \\\n",
       "0    Singapore’s GIC Buying Stake In London’s Paddi...   \n",
       "1    What You Should Know Before Investing In Fidel...   \n",
       "2    Student Loan Forgiveness: 4 People Likely To O...   \n",
       "3    Home Buying Is Becoming ‘Unaffordable For Most...   \n",
       "4    Examining The Ukrainian Tax Implications Of Ru...   \n",
       "..                                                 ...   \n",
       "406  Analyst Believes Bitcoin Could Soon Fall To $3...   \n",
       "407          The Best Mid-Cap Dividend Stocks For 2022   \n",
       "408  How To Optimize The Energy We Put Into Financi...   \n",
       "409  Ask Larry: Will The 2022 COLA Apply To Benefit...   \n",
       "410  Singapore Tycoon Kwek Leng Beng’s CDL Suburban...   \n",
       "\n",
       "                                                  desc              author  \\\n",
       "0    Singaporean sovereign wealth fund GIC has agre...     Jonathan Burgos   \n",
       "1    This morning crypto advocates and the crypto c...      Steven Ehrlich   \n",
       "2    Here are 4 people who are likely to oppose mas...       Zack Friedman   \n",
       "3    Monthly mortgage payments are up nearly $500 s...    Sergei Klebnikov   \n",
       "4    Valeria Tarasenko of Dentons Kyiv discusses th...     Tax Notes Staff   \n",
       "..                                                 ...                 ...   \n",
       "406  Carter Braxton Worth, a technical analyst, bel...         Chuck Jones   \n",
       "407  Mid-cap dividend stocks are the best bargain o...         Brett Owens   \n",
       "408  Studies suggest that up to 80% of financial pl...          Tim Maurer   \n",
       "409  Today's Social Security column addresses quest...  Laurence Kotlikoff   \n",
       "410  City Developments has sold 77% of its resident...     Jonathan Burgos   \n",
       "\n",
       "                                               content  \n",
       "0    Singapore’s GIC Buying Stake In London’s Paddi...  \n",
       "1    What You Should Know Before Investing In Fidel...  \n",
       "2    Student Loan Forgiveness: 4 People Likely To O...  \n",
       "3    Home Buying Is Becoming ‘Unaffordable For Most...  \n",
       "4    Examining The Ukrainian Tax Implications Of Ru...  \n",
       "..                                                 ...  \n",
       "406  Analyst Believes Bitcoin Could Soon Fall To $3...  \n",
       "407  The Best Mid-Cap Dividend Stocks For 2022. Mid...  \n",
       "408  How To Optimize The Energy We Put Into Financi...  \n",
       "409  Ask Larry: Will The 2022 COLA Apply To Benefit...  \n",
       "410  Singapore Tycoon Kwek Leng Beng’s CDL Suburban...  \n",
       "\n",
       "[411 rows x 7 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news['category'] = np.where(news.category == 'Metaverse', 'Cryptocurrencies', news.category)\n",
    "news['content'] = news[\"header\"] + \". \" + news[\"desc\"]\n",
    "news_target_date = filter_news_by_date(start, end, news)\n",
    "news_target_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dde833",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_result = pd.DataFrame()\n",
    "fieldnames = ['date','category','content', 'sentiment_score']\n",
    "\n",
    "for index, row in news_target_date.iterrows():\n",
    "    date = row['date']\n",
    "    content = preprocess_word(row['content'])\n",
    "    category = row['category']\n",
    "    \n",
    "    predict_content = predict(content, model, use_gpu=True, gpu_name='cuda:0',batch_size=100)\n",
    "    sentiment_score = predict_content.sentiment_score.mean()\n",
    "    \n",
    "    value = [(date, category, content, sentiment_score)]\n",
    "    \n",
    "    record = pd.DataFrame(value, columns=fieldnames)\n",
    "    sentiment_result = pd.concat([sentiment_result, record], ignore_index=True, axis=0)\n",
    "\n",
    "sentiment_result\n",
    "sentiment_result.to_csv(r\"data/{0}_sentiment.csv\".format('New_News'), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a17a9f",
   "metadata": {},
   "source": [
    "# Generate announcement sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d77e1874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentiment(data, symbol):\n",
    "    \n",
    "    data[\"Process Content\"] = data[\"Content\"].apply(lambda x: preprocess_word(x))\n",
    "    data[\"Date\"] = data[\"Date\"].apply(lambda x: pd.to_datetime(x, unit=\"ns\", utc=True).floor('D').date())\n",
    "    data = data.drop(['AuthorID','Author','Content', 'Attachments','Reactions'], axis=1)\n",
    "    data = data.reset_index()\n",
    "    sentiment_result = pd.DataFrame()\n",
    "    fieldnames = ['symbol','date', 'content', 'sentiment_score']\n",
    "    for index, row in data.iterrows():\n",
    "        percent_complete(int(index), int(data.shape[0]),title=\"{0}: Predicting text sentiment analysis\".format(symbol))\n",
    "        symbol = symbol\n",
    "        date = row['Date']\n",
    "        content = row['Process Content']\n",
    "        predict_content = predict(row['Process Content'], model, use_gpu=True, gpu_name='cuda:0',batch_size=100)\n",
    "        sentiment_score = predict_content.sentiment_score.mean()\n",
    "    \n",
    "        value = [(symbol, date, content, sentiment_score)]\n",
    "    \n",
    "        record = pd.DataFrame(value, columns=fieldnames)\n",
    "        sentiment_result = pd.concat([sentiment_result, record], ignore_index=True, axis=0)\n",
    "\n",
    "\n",
    "    sentiment_result\n",
    "    sentiment_result.to_csv(r\"data/{0}_sentiment.csv\".format(symbol), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e865962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_complete(step, total_steps, bar_width=60, title=\"\", print_perc=True):\n",
    "    import sys\n",
    "\n",
    "    # UTF-8 left blocks: 1, 1/8, 1/4, 3/8, 1/2, 5/8, 3/4, 7/8\n",
    "    utf_8s = [\"█\", \"▏\", \"▎\", \"▍\", \"▌\", \"▋\", \"▊\", \"█\"]\n",
    "    perc = 100 * float(step) / float(total_steps)\n",
    "    max_ticks = bar_width * 8\n",
    "    num_ticks = int(round(perc / 100 * max_ticks))\n",
    "    full_ticks = num_ticks / 8      # Number of full blocks\n",
    "    part_ticks = num_ticks % 8      # Size of partial block (array index)\n",
    "    \n",
    "    disp = bar = \"\"                 # Blank out variables\n",
    "    bar += utf_8s[0] * int(full_ticks)   # Add full blocks into Progress Bar\n",
    "    \n",
    "    # If part_ticks is zero, then no partial block, else append part char\n",
    "    if part_ticks > 0:\n",
    "        bar += utf_8s[part_ticks]\n",
    "    \n",
    "    # Pad Progress Bar with fill character\n",
    "    bar += \"▒\" * int((max_ticks/8 - float(num_ticks)/8.0))\n",
    "    \n",
    "    if len(title) > 0:\n",
    "        disp = title + \": \"         # Optional title to progress display\n",
    "    \n",
    "    # Print progress bar in green: https://stackoverflow.com/a/21786287/6929343\n",
    "    disp += \"\\x1b[0;32m\"            # Color Green\n",
    "    disp += bar                     # Progress bar to progress display\n",
    "    disp += \"\\x1b[0m\"               # Color Reset\n",
    "    if print_perc:\n",
    "        # If requested, append percentage complete to progress display\n",
    "        if perc > 100.0:\n",
    "            perc = 100.0            # Fix \"100.04 %\" rounding error\n",
    "        disp += \" {:6.2f}\".format(perc) + \" %\"\n",
    "    \n",
    "    # Output to terminal repetitively over the same line using '\\r'.\n",
    "    sys.stdout.write(\"\\r\" + disp)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3030b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "StepN = pd.read_csv(r\"data/STEPN_new_Announcement.csv\")\n",
    "generate_sentiment(StepN,'new_STEPN_Announcement')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3624ffc4",
   "metadata": {},
   "source": [
    "# Generate general sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07b6798",
   "metadata": {},
   "outputs": [],
   "source": [
    "StepN = pd.read_csv(r\"data/STEPN_new_general.csv\")\n",
    "generate_sentiment(StepN,'new_STEPN_General')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2db8a82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
